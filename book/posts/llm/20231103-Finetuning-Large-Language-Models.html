<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>20231103-Finetuning-Large-Language-Models - alanhc-til</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../../favicon.svg">
        <link rel="shortcut icon" href="../../favicon.png">
        <link rel="stylesheet" href="../../css/variables.css">
        <link rel="stylesheet" href="../../css/general.css">
        <link rel="stylesheet" href="../../css/chrome.css">
        <link rel="stylesheet" href="../../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../../highlight.css">
        <link rel="stylesheet" href="../../tomorrow-night.css">
        <link rel="stylesheet" href="../../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../../posts/20231210-convert-post-markdown.html"><strong aria-hidden="true">1.</strong> 20231210-convert-post-markdown</a></li><li class="chapter-item expanded "><a href="../../posts/20231213-pyspark.html"><strong aria-hidden="true">2.</strong> 20231213-pyspark</a></li><li class="chapter-item expanded "><a href="../../posts/20231217-google-gemini.html"><strong aria-hidden="true">3.</strong> 20231217-google-gemini</a></li><li class="chapter-item expanded "><a href="../../posts/20231217-ntu-matches.html"><strong aria-hidden="true">4.</strong> 20231217-ntu-matches</a></li><li class="chapter-item expanded "><a href="../../posts/20231222-chat.html"><strong aria-hidden="true">5.</strong> 20231222-chat</a></li><li class="chapter-item expanded "><a href="../../posts/20240107-notion-website.html"><strong aria-hidden="true">6.</strong> 20240107-notion-website</a></li><li class="chapter-item expanded "><a href="../../posts/20240108-attention.html"><strong aria-hidden="true">7.</strong> 20240108-attention</a></li><li class="chapter-item expanded "><a href="../../posts/20240113-data-engineer-salary.html"><strong aria-hidden="true">8.</strong> 20240113-data-engineer-salary</a></li><li class="chapter-item expanded "><a href="../../posts/20240119-OSINT.html"><strong aria-hidden="true">9.</strong> 20240119-OSINT</a></li><li class="chapter-item expanded "><a href="../../posts/20240122-english-speaking.html"><strong aria-hidden="true">10.</strong> 20240122-english-speaking</a></li><li class="chapter-item expanded "><a href="../../posts/20240122-ntu-cool-video-download.html"><strong aria-hidden="true">11.</strong> 20240122-ntu-cool-video-download</a></li><li class="chapter-item expanded "><a href="../../posts/20240122-stock-data-design.html"><strong aria-hidden="true">12.</strong> 20240122-stock-data-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240123-scalper.html"><strong aria-hidden="true">13.</strong> 20240123-scalper</a></li><li class="chapter-item expanded "><a href="../../posts/20240124-break-cloudflare-bot-prevention.html"><strong aria-hidden="true">14.</strong> 20240124-break-cloudflare-bot-prevention</a></li><li class="chapter-item expanded "><a href="../../posts/20240125-cache-design.html"><strong aria-hidden="true">15.</strong> 20240125-cache-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240125-duplicate-url-design.html"><strong aria-hidden="true">16.</strong> 20240125-duplicate-url-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240125-web-crawler-design.html"><strong aria-hidden="true">17.</strong> 20240125-web-crawler-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240203-trading-bot.html"><strong aria-hidden="true">18.</strong> 20240203-trading-bot</a></li><li class="chapter-item expanded "><a href="../../posts/20240205-salesrank-design.html"><strong aria-hidden="true">19.</strong> 20240205-salesrank-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240209-job-insights.html"><strong aria-hidden="true">20.</strong> 20240209-job-insights</a></li><li class="chapter-item expanded "><a href="../../posts/20240211-pastebin-design.html"><strong aria-hidden="true">21.</strong> 20240211-pastebin-design</a></li><li class="chapter-item expanded "><a href="../../posts/20240211-taiwan-job-insights.html"><strong aria-hidden="true">22.</strong> 20240211-taiwan-job-insights</a></li><li class="chapter-item expanded "><a href="../../posts/20240212-linkedin-private-api.html"><strong aria-hidden="true">23.</strong> 20240212-linkedin-private-api</a></li><li class="chapter-item expanded "><a href="../../posts/20240215-Deck-of-cards-ood.html"><strong aria-hidden="true">24.</strong> 20240215-Deck-of-cards-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240216-levelsfyi-crawler.html"><strong aria-hidden="true">25.</strong> 20240216-levelsfyi-crawler</a></li><li class="chapter-item expanded "><a href="../../posts/20240217-call-center-ood.html"><strong aria-hidden="true">26.</strong> 20240217-call-center-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240217-jigsaw-ood.html"><strong aria-hidden="true">27.</strong> 20240217-jigsaw-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240217-jukebox-ood.html"><strong aria-hidden="true">28.</strong> 20240217-jukebox-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240217-online-book-reader-ood.html"><strong aria-hidden="true">29.</strong> 20240217-online-book-reader-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240217-parking-lot-ood.html"><strong aria-hidden="true">30.</strong> 20240217-parking-lot-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240219-chat-server-ood.html"><strong aria-hidden="true">31.</strong> 20240219-chat-server-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240221-othello-ood.html"><strong aria-hidden="true">32.</strong> 20240221-othello-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240222-text-network-analysis.html"><strong aria-hidden="true">33.</strong> 20240222-text-network-analysis</a></li><li class="chapter-item expanded "><a href="../../posts/20240226-Circular-array-ood.html"><strong aria-hidden="true">34.</strong> 20240226-Circular-array-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240226-minesweeper-ood.html"><strong aria-hidden="true">35.</strong> 20240226-minesweeper-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240227-File-Systems-ood.html"><strong aria-hidden="true">36.</strong> 20240227-File-Systems-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240227-Hash-Table-ood.html"><strong aria-hidden="true">37.</strong> 20240227-Hash-Table-ood</a></li><li class="chapter-item expanded "><a href="../../posts/20240227-huggingface-nlp.html"><strong aria-hidden="true">38.</strong> 20240227-huggingface-nlp</a></li><li class="chapter-item expanded "><a href="../../posts/20240227-warp-terminal.html"><strong aria-hidden="true">39.</strong> 20240227-warp-terminal</a></li><li class="chapter-item expanded "><a href="../../posts/20240303-save-password-python.html"><strong aria-hidden="true">40.</strong> 20240303-save-password-python</a></li><li class="chapter-item expanded "><a href="../../posts/20240321-interview-warmup.html"><strong aria-hidden="true">41.</strong> 20240321-interview-warmup</a></li><li class="chapter-item expanded "><a href="../../posts/20240324-learn-go.html"><strong aria-hidden="true">42.</strong> 20240324-learn-go</a></li><li class="chapter-item expanded "><a href="../../posts/20240409-你要如何衡量你的人生.html"><strong aria-hidden="true">43.</strong> 20240409-你要如何衡量你的人生</a></li><li class="chapter-item expanded "><a href="../../posts/20240621-公雲學習筆記.html"><strong aria-hidden="true">44.</strong> 20240621-公雲學習筆記</a></li><li class="chapter-item expanded "><a href="../../posts/20240716-BuildingYourOwnDatabaseAgent.html"><strong aria-hidden="true">45.</strong> 20240716-BuildingYourOwnDatabaseAgent</a></li><li class="chapter-item expanded "><a href="../../posts/HuggingFaceLLM.html"><strong aria-hidden="true">46.</strong> HuggingFaceLLM</a></li><li class="chapter-item expanded affix "><li class="part-title">ai</li><li class="chapter-item expanded "><a href="../../posts/ai/20231028-mozilla-ai.html"><strong aria-hidden="true">47.</strong> 20231028-mozilla-ai</a></li><li class="chapter-item expanded "><a href="../../posts/ai/20231209-AI-music-example.html"><strong aria-hidden="true">48.</strong> 20231209-AI-music-example</a></li><li class="chapter-item expanded affix "><li class="part-title">backend</li><li class="chapter-item expanded "><a href="../../posts/backend/20231006-fastapi-streaming.html"><strong aria-hidden="true">49.</strong> 20231006-fastapi-streaming</a></li><li class="chapter-item expanded affix "><li class="part-title">blockchain</li><li class="chapter-item expanded "><a href="../../posts/blockchain/20221228-solana-nft-tutorial.html"><strong aria-hidden="true">50.</strong> 20221228-solana-nft-tutorial</a></li><li class="chapter-item expanded "><a href="../../posts/blockchain/20230824-bigchain.html"><strong aria-hidden="true">51.</strong> 20230824-bigchain</a></li><li class="chapter-item expanded "><a href="../../posts/blockchain/20231104-learn-cosmos.html"><strong aria-hidden="true">52.</strong> 20231104-learn-cosmos</a></li><li class="chapter-item expanded affix "><li class="part-title">bot</li><li class="chapter-item expanded "><a href="../../posts/bot/20231202-twitter-bot.html"><strong aria-hidden="true">53.</strong> 20231202-twitter-bot</a></li><li class="chapter-item expanded affix "><li class="part-title">c_c++</li><li class="chapter-item expanded "><a href="../../posts/c_c++/20171210-vector.html"><strong aria-hidden="true">54.</strong> 20171210-vector</a></li><li class="chapter-item expanded "><a href="../../posts/c_c++/20180124-gets-puts.html"><strong aria-hidden="true">55.</strong> 20180124-gets-puts</a></li><li class="chapter-item expanded affix "><li class="part-title">class_notes</li><li class="chapter-item expanded "><a href="../../posts/class_notes/*.html"><strong aria-hidden="true">56.</strong> *</a></li><li class="chapter-item expanded affix "><li class="part-title">cloudflare</li><li class="chapter-item expanded "><a href="../../posts/cloudflare/20231125-cloudflare-tunnel.html"><strong aria-hidden="true">57.</strong> 20231125-cloudflare-tunnel</a></li><li class="chapter-item expanded affix "><li class="part-title">competative_programing</li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20171221-uva10190.html"><strong aria-hidden="true">58.</strong> 20171221-uva10190</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180128-uva10931.html"><strong aria-hidden="true">59.</strong> 20180128-uva10931</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180131-uva11917.html"><strong aria-hidden="true">60.</strong> 20180131-uva11917</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180205-uva10405.html"><strong aria-hidden="true">61.</strong> 20180205-uva10405</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180206-uva10162.html"><strong aria-hidden="true">62.</strong> 20180206-uva10162</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180209-uva406.html"><strong aria-hidden="true">63.</strong> 20180209-uva406</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180210-NCTU-PCCA-winter-notes.html"><strong aria-hidden="true">64.</strong> 20180210-NCTU-PCCA-winter-notes</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180212-uva10611.html"><strong aria-hidden="true">65.</strong> 20180212-uva10611</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180222-uva401.html"><strong aria-hidden="true">66.</strong> 20180222-uva401</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180309-uva141.html"><strong aria-hidden="true">67.</strong> 20180309-uva141</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180312-uva10190.html"><strong aria-hidden="true">68.</strong> 20180312-uva10190</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180314-uva105.html"><strong aria-hidden="true">69.</strong> 20180314-uva105</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180317-uva10409.html"><strong aria-hidden="true">70.</strong> 20180317-uva10409</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20180405-uva630.html"><strong aria-hidden="true">71.</strong> 20180405-uva630</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/20190409-uva409.html"><strong aria-hidden="true">72.</strong> 20190409-uva409</a></li><li class="chapter-item expanded "><a href="../../posts/competative_programing/閱讀筆記-競技程式路線圖.html"><strong aria-hidden="true">73.</strong> 閱讀筆記-競技程式路線圖</a></li><li class="chapter-item expanded affix "><li class="part-title">computer_graphics</li><li class="chapter-item expanded "><a href="../../posts/computer_graphics/20190614-CGfinal.html"><strong aria-hidden="true">74.</strong> 20190614-CGfinal</a></li><li class="chapter-item expanded affix "><li class="part-title">crawler</li><li class="chapter-item expanded "><a href="../../posts/crawler/20230813-back-up-crawler.html"><strong aria-hidden="true">75.</strong> 20230813-back-up-crawler</a></li><li class="chapter-item expanded "><a href="../../posts/crawler/20240121-Web-Scraping-Instagram-with-Selenium.html"><strong aria-hidden="true">76.</strong> 20240121-Web-Scraping-Instagram-with-Selenium</a></li><li class="chapter-item expanded affix "><li class="part-title">db</li><li class="chapter-item expanded "><a href="../../posts/db/20230831-mongodb-aggregate-multiple-group.html"><strong aria-hidden="true">77.</strong> 20230831-mongodb-aggregate-multiple-group</a></li><li class="chapter-item expanded affix "><li class="part-title">devops</li><li class="chapter-item expanded "><a href="../../posts/devops/20231124-terraform-vercel.html"><strong aria-hidden="true">78.</strong> 20231124-terraform-vercel</a></li><li class="chapter-item expanded affix "><li class="part-title">docker</li><li class="chapter-item expanded "><a href="../../posts/docker/20231209-docker-machine-learning.html"><strong aria-hidden="true">79.</strong> 20231209-docker-machine-learning</a></li><li class="chapter-item expanded affix "><li class="part-title">dsa</li><li class="chapter-item expanded "><a href="../../posts/dsa/20171217-DP.html"><strong aria-hidden="true">80.</strong> 20171217-DP</a></li><li class="chapter-item expanded "><a href="../../posts/dsa/20171219-recursion.html"><strong aria-hidden="true">81.</strong> 20171219-recursion</a></li><li class="chapter-item expanded "><a href="../../posts/dsa/20171230-recursion.html"><strong aria-hidden="true">82.</strong> 20171230-recursion</a></li><li class="chapter-item expanded "><a href="../../posts/dsa/20180209-linked-list.html"><strong aria-hidden="true">83.</strong> 20180209-linked-list</a></li><li class="chapter-item expanded "><a href="../../posts/dsa/20180228-hash-table.html"><strong aria-hidden="true">84.</strong> 20180228-hash-table</a></li><li class="chapter-item expanded "><a href="../../posts/dsa/20231103-linklist.html"><strong aria-hidden="true">85.</strong> 20231103-linklist</a></li><li class="chapter-item expanded "><a href="../../posts/fastapi-k8s.html"><strong aria-hidden="true">86.</strong> fastapi-k8s</a></li><li class="chapter-item expanded "><a href="../../posts/first-day.html"><strong aria-hidden="true">87.</strong> first-day</a></li><li class="chapter-item expanded affix "><li class="part-title">frontend</li><li class="chapter-item expanded "><a href="../../posts/frontend/20230812-react-syntax-clipboard.html"><strong aria-hidden="true">88.</strong> 20230812-react-syntax-clipboard</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230816-nprogress.html"><strong aria-hidden="true">89.</strong> 20230816-nprogress</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230817-next-sitemap.html"><strong aria-hidden="true">90.</strong> 20230817-next-sitemap</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230818-markdown-section-link.html"><strong aria-hidden="true">91.</strong> 20230818-markdown-section-link</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230819-mermaid-js.html"><strong aria-hidden="true">92.</strong> 20230819-mermaid-js</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230820-nexjs13.html"><strong aria-hidden="true">93.</strong> 20230820-nexjs13</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230824-chakra-darkmode.html"><strong aria-hidden="true">94.</strong> 20230824-chakra-darkmode</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230825-rss.html"><strong aria-hidden="true">95.</strong> 20230825-rss</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230826-import-alias.html"><strong aria-hidden="true">96.</strong> 20230826-import-alias</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230826-next-seo.html"><strong aria-hidden="true">97.</strong> 20230826-next-seo</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230827-chat-app.html"><strong aria-hidden="true">98.</strong> 20230827-chat-app</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230827-next-pwa.html"><strong aria-hidden="true">99.</strong> 20230827-next-pwa</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230829-chakra-ui.html"><strong aria-hidden="true">100.</strong> 20230829-chakra-ui</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230830-nextjs-google-analytics.html"><strong aria-hidden="true">101.</strong> 20230830-nextjs-google-analytics</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230831-kbar.html"><strong aria-hidden="true">102.</strong> 20230831-kbar</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230831-mdx.html"><strong aria-hidden="true">103.</strong> 20230831-mdx</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230907-react-native.html"><strong aria-hidden="true">104.</strong> 20230907-react-native</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230924-QR-Code.html"><strong aria-hidden="true">105.</strong> 20230924-QR-Code</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230924-wagami.html"><strong aria-hidden="true">106.</strong> 20230924-wagami</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20230929-rn-qrcode.html"><strong aria-hidden="true">107.</strong> 20230929-rn-qrcode</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20231010-webauthn.html"><strong aria-hidden="true">108.</strong> 20231010-webauthn</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20231107-MUI-toolpad.html"><strong aria-hidden="true">109.</strong> 20231107-MUI-toolpad</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20231107-imgbb.html"><strong aria-hidden="true">110.</strong> 20231107-imgbb</a></li><li class="chapter-item expanded "><a href="../../posts/frontend/20231112-nextjs-upload-large-file.html"><strong aria-hidden="true">111.</strong> 20231112-nextjs-upload-large-file</a></li><li class="chapter-item expanded affix "><li class="part-title">genai</li><li class="chapter-item expanded "><a href="../../posts/genai/20231108-How-Diffusion-Models-Work.html"><strong aria-hidden="true">112.</strong> 20231108-How-Diffusion-Models-Work</a></li><li class="chapter-item expanded "><a href="../../posts/genai/20231110-生成式AI淺談圖像生成模型-Diffusion-Model-原理.html"><strong aria-hidden="true">113.</strong> 20231110-生成式AI淺談圖像生成模型-Diffusion-Model-原理</a></li><li class="chapter-item expanded affix "><li class="part-title">jobs</li><li class="chapter-item expanded "><a href="../../posts/jobs/20220811-LINE-Blockchain-Developer-Intern.html"><strong aria-hidden="true">114.</strong> 20220811-LINE-Blockchain-Developer-Intern</a></li><li class="chapter-item expanded affix "><li class="part-title">kubenetes</li><li class="chapter-item expanded "><a href="../../posts/kubenetes/20221231-k8s-notes.html"><strong aria-hidden="true">115.</strong> 20221231-k8s-notes</a></li><li class="chapter-item expanded affix "><li class="part-title">learning</li><li class="chapter-item expanded "><a href="../../posts/learning/20231023-learning-from-lin.html"><strong aria-hidden="true">116.</strong> 20231023-learning-from-lin</a></li><li class="chapter-item expanded affix "><li class="part-title">llm</li><li class="chapter-item expanded "><a href="../../posts/llm/20231023-Pair-Programming-with-a-Large-Language-Model.html"><strong aria-hidden="true">117.</strong> 20231023-Pair-Programming-with-a-Large-Language-Model</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231026-ChatGPT-Prompt-Engineering-for-Developers.html"><strong aria-hidden="true">118.</strong> 20231026-ChatGPT-Prompt-Engineering-for-Developers</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231029-Building-Systems-with-the-ChatGPT-API.html"><strong aria-hidden="true">119.</strong> 20231029-Building-Systems-with-the-ChatGPT-API</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231031-Andrew-Ng-Opportunities-in-AI-2023.html"><strong aria-hidden="true">120.</strong> 20231031-Andrew-Ng-Opportunities-in-AI-2023</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231101-generative-ai-for-everyone.html"><strong aria-hidden="true">121.</strong> 20231101-generative-ai-for-everyone</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231103-Finetuning-Large-Language-Models.html" class="active"><strong aria-hidden="true">122.</strong> 20231103-Finetuning-Large-Language-Models</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231110-80分鐘快速了解大型語言模型-5-30有咒術迴戰雷.html"><strong aria-hidden="true">123.</strong> 20231110-80分鐘快速了解大型語言模型-5-30有咒術迴戰雷</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231129-ShouldYouUseOpenSourceLargeLanguageModels?.html"><strong aria-hidden="true">124.</strong> 20231129-ShouldYouUseOpenSourceLargeLanguageModels?</a></li><li class="chapter-item expanded "><a href="../../posts/llm/20231130-Building-and-Evaluating-Advanced-RAG.html"><strong aria-hidden="true">125.</strong> 20231130-Building-and-Evaluating-Advanced-RAG</a></li><li class="chapter-item expanded "><a href="../../posts/llm-k8s.html"><strong aria-hidden="true">126.</strong> llm-k8s</a></li><li class="chapter-item expanded affix "><li class="part-title">maker</li><li class="chapter-item expanded "><a href="../../posts/maker/20171105-makerfair.html"><strong aria-hidden="true">127.</strong> 20171105-makerfair</a></li><li class="chapter-item expanded affix "><li class="part-title">monorepo</li><li class="chapter-item expanded "><a href="../../posts/monorepo/20220721-upgrade-nx-repo-to-react-18.html"><strong aria-hidden="true">128.</strong> 20220721-upgrade-nx-repo-to-react-18</a></li><li class="chapter-item expanded "><a href="../../posts/monorepo/20220811-monorepo-development.html"><strong aria-hidden="true">129.</strong> 20220811-monorepo-development</a></li><li class="chapter-item expanded "><a href="../../posts/monorepo/20230920-nx.html"><strong aria-hidden="true">130.</strong> 20230920-nx</a></li><li class="chapter-item expanded "><a href="../../posts/nextjs-markdown.html"><strong aria-hidden="true">131.</strong> nextjs-markdown</a></li><li class="chapter-item expanded "><a href="../../posts/nextjs.html"><strong aria-hidden="true">132.</strong> nextjs</a></li><li class="chapter-item expanded affix "><li class="part-title">nft</li><li class="chapter-item expanded "><a href="../../posts/nft/20221230-tezos-nft-tutorial.html"><strong aria-hidden="true">133.</strong> 20221230-tezos-nft-tutorial</a></li><li class="chapter-item expanded "><a href="../../posts/nft/20230108-solidity-nft.html"><strong aria-hidden="true">134.</strong> 20230108-solidity-nft</a></li><li class="chapter-item expanded "><a href="../../posts/nft/20230109-ipfs-upload.html"><strong aria-hidden="true">135.</strong> 20230109-ipfs-upload</a></li><li class="chapter-item expanded affix "><li class="part-title">programing</li><li class="chapter-item expanded "><a href="../../posts/programing/20171027-bnf.html"><strong aria-hidden="true">136.</strong> 20171027-bnf</a></li><li class="chapter-item expanded "><a href="../../posts/programing/20171106-gcd.html"><strong aria-hidden="true">137.</strong> 20171106-gcd</a></li><li class="chapter-item expanded "><a href="../../posts/programing/20180123-int2str.html"><strong aria-hidden="true">138.</strong> 20180123-int2str</a></li><li class="chapter-item expanded affix "><li class="part-title">projects</li><li class="chapter-item expanded "><a href="../../posts/projects/20210820-開發mcu-up-銘傳金手指3-0-的那些事兒.html"><strong aria-hidden="true">139.</strong> 20210820-開發mcu-up-銘傳金手指3-0-的那些事兒</a></li><li class="chapter-item expanded "><a href="../../posts/projects/20220531-Decentral-Showroom-NTU-DApp-Term-project.html"><strong aria-hidden="true">140.</strong> 20220531-Decentral-Showroom-NTU-DApp-Term-project</a></li><li class="chapter-item expanded "><a href="../../posts/python使用pyinstaller製作桌面應用程式.html"><strong aria-hidden="true">141.</strong> python使用pyinstaller製作桌面應用程式</a></li><li class="chapter-item expanded "><a href="../../posts/quotes.html"><strong aria-hidden="true">142.</strong> quotes</a></li><li class="chapter-item expanded affix "><li class="part-title">security</li><li class="chapter-item expanded "><a href="../../posts/security/20171102-computer-virus.html"><strong aria-hidden="true">143.</strong> 20171102-computer-virus</a></li><li class="chapter-item expanded affix "><li class="part-title">shell</li><li class="chapter-item expanded "><a href="../../posts/shell/20230924-cmd-copy.html"><strong aria-hidden="true">144.</strong> 20230924-cmd-copy</a></li><li class="chapter-item expanded affix "><li class="part-title">software_engineering</li><li class="chapter-item expanded "><a href="../../posts/software_engineering/20171027-refactor.html"><strong aria-hidden="true">145.</strong> 20171027-refactor</a></li><li class="chapter-item expanded "><a href="../../posts/software_engineering/20171202-styleguide.html"><strong aria-hidden="true">146.</strong> 20171202-styleguide</a></li><li class="chapter-item expanded affix "><li class="part-title">startup</li><li class="chapter-item expanded "><a href="../../posts/startup/20230926-21-things-before-21.html"><strong aria-hidden="true">147.</strong> 20230926-21-things-before-21</a></li><li class="chapter-item expanded "><a href="../../posts/startup/20231115-How-to-Build-An-MVP-Startup-School.html"><strong aria-hidden="true">148.</strong> 20231115-How-to-Build-An-MVP-Startup-School</a></li><li class="chapter-item expanded affix "><li class="part-title">tools</li><li class="chapter-item expanded "><a href="../../posts/tools/20180119-hackmd.html"><strong aria-hidden="true">149.</strong> 20180119-hackmd</a></li><li class="chapter-item expanded "><a href="../../posts/tools/20230826-imgur.html"><strong aria-hidden="true">150.</strong> 20230826-imgur</a></li><li class="chapter-item expanded "><a href="../../posts/tools/20230827-notion-alternative.html"><strong aria-hidden="true">151.</strong> 20230827-notion-alternative</a></li><li class="chapter-item expanded affix "><li class="part-title">vector_database</li><li class="chapter-item expanded "><a href="../../posts/vector_database/20231115-Building-Multi-Modal-Search-with-Vector-Databases.html"><strong aria-hidden="true">152.</strong> 20231115-Building-Multi-Modal-Search-with-Vector-Databases</a></li><li class="chapter-item expanded "><a href="../../posts/vector_database/20231116-Vector-Databases-from-Embeddings-to-Applications.html"><strong aria-hidden="true">153.</strong> 20231116-Vector-Databases-from-Embeddings-to-Applications</a></li><li class="chapter-item expanded affix "><li class="part-title">vscode</li><li class="chapter-item expanded "><a href="../../posts/vscode/20230827-vscode-animate-extension.html"><strong aria-hidden="true">154.</strong> 20230827-vscode-animate-extension</a></li><li class="chapter-item expanded affix "><li class="part-title">web3</li><li class="chapter-item expanded "><a href="../../posts/web3/20211011-虛擬人課堂筆記-spark-ar.html"><strong aria-hidden="true">155.</strong> 20211011-虛擬人課堂筆記-spark-ar</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20211018-虛擬人課堂筆記2.html"><strong aria-hidden="true">156.</strong> 20211018-虛擬人課堂筆記2</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20211027-虛擬人課堂筆記3-unity-facecapture.html"><strong aria-hidden="true">157.</strong> 20211027-虛擬人課堂筆記3-unity-facecapture</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20211028-虛擬人課堂筆記4-vroid.html"><strong aria-hidden="true">158.</strong> 20211028-虛擬人課堂筆記4-vroid</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20220518-web3-世界裡的驗證機制-以Tezos為例.html"><strong aria-hidden="true">159.</strong> 20220518-web3-世界裡的驗證機制-以Tezos為例</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20230827-orbitdb.html"><strong aria-hidden="true">160.</strong> 20230827-orbitdb</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20230828-ipfs.html"><strong aria-hidden="true">161.</strong> 20230828-ipfs</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20230828-libp2p.html"><strong aria-hidden="true">162.</strong> 20230828-libp2p</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20230829-orbit-chat.html"><strong aria-hidden="true">163.</strong> 20230829-orbit-chat</a></li><li class="chapter-item expanded "><a href="../../posts/web3/20230919-hardhat.html"><strong aria-hidden="true">164.</strong> 20230919-hardhat</a></li><li class="chapter-item expanded affix "><li class="part-title">webrtc</li><li class="chapter-item expanded "><a href="../../posts/webrtc/20230829-peerjs.html"><strong aria-hidden="true">165.</strong> 20230829-peerjs</a></li><li class="chapter-item expanded "><a href="../../posts/windows下的套件管理-Chocolatey.html"><strong aria-hidden="true">166.</strong> windows下的套件管理-Chocolatey</a></li><li class="chapter-item expanded "><a href="../../posts/超簡單!一文理解如何使用私有大型語言模型LLM-Ollama＋OpenWebUI篇.html"><strong aria-hidden="true">167.</strong> 超簡單!一文理解如何使用私有大型語言模型LLM-Ollama＋OpenWebUI篇</a></li><li class="chapter-item expanded "><a href="../../posts/閱讀筆記-建中2021校內培訓簡報.html"><strong aria-hidden="true">168.</strong> 閱讀筆記-建中2021校內培訓簡報</a></li><li class="chapter-item expanded "><a href="../../posts/閱讀筆記-建中2021暑假資讀投影片-謝一.html"><strong aria-hidden="true">169.</strong> 閱讀筆記-建中2021暑假資讀投影片-謝一</a></li><li class="chapter-item expanded "><a href="../../posts/國外工作.html"><strong aria-hidden="true">170.</strong> 國外工作</a></li><li class="chapter-item expanded "><a href="../../posts/更快的影片學習方法.html"><strong aria-hidden="true">171.</strong> 更快的影片學習方法</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">alanhc-til</h1>

                    <div class="right-buttons">
                        <a href="../../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <hr />
<p>title: 20231103-Finetuning-Large-Language-Models
date: 2023-11-03
tags:</p>
<ul>
<li>llm</li>
</ul>
<hr />
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<ul>
<li>why?
<ul>
<li>要學某種語氣等等要使用
<img src="https://i.imgur.com/eRJk6Wv.png" alt="" /></li>
</ul>
</li>
</ul>
<h2 id="why-finetune"><a class="header" href="#why-finetune">Why finetune</a></h2>
<p><img src="https://i.imgur.com/BDIrVE7.png" alt="" /></p>
<p><img src="https://i.imgur.com/slOU3pq.png" alt="" /></p>
<p><img src="https://i.imgur.com/2ET8sWn.png" alt="" /></p>
<p><img src="https://i.imgur.com/4XkCOKr.png" alt="" /></p>
<p><img src="https://i.imgur.com/aZP4Skf.png" alt="" /></p>
<p><img src="https://i.imgur.com/qJhOvTv.png" alt="" /></p>
<pre><code class="language-python">from llama import BasicModelRunner
# Try Non-Finetuned models
non_finetuned = BasicModelRunner("meta-llama/Llama-2-7b-hf")
non_finetuned_output = non_finetuned("Tell me how to train my dog to sit")
print(non_finetuned_output)



print(non_finetuned("What do you think of Mars?"))
print(non_finetuned("taylor swift's best friend"))
print(non_finetuned("""Agent: I'm here to help you with your Amazon deliver order.
Customer: I didn't get my item
Agent: I'm sorry to hear that. Which item was it?
Customer: the blanket
Agent:"""))
# Compare to finetuned models
finetuned_model = BasicModelRunner("meta-llama/Llama-2-7b-chat-hf")
finetuned_output = finetuned_model("Tell me how to train my dog to sit")
print(finetuned_output)
print(finetuned_model("[INST]Tell me how to train my dog to sit[/INST]"))
print(non_finetuned("[INST]Tell me how to train my dog to sit[/INST]"))
print(finetuned_model("What do you think of Mars?"))
print(finetuned_model("taylor swift's best friend"))
print(finetuned_model("""Agent: I'm here to help you with your Amazon deliver order.
Customer: I didn't get my item
Agent: I'm sorry to hear that. Which item was it?
Customer: the blanket
Agent:"""))
#  Compare to ChatGPT
chatgpt = BasicModelRunner("chat-gpt")
print(chatgpt("Tell me how to train my dog to sit"))

</code></pre>
<h2 id="where-fineturning-fits-in"><a class="header" href="#where-fineturning-fits-in">where fineturning fits in</a></h2>
<p><img src="https://i.imgur.com/1z7cMZ0.png" alt="" /></p>
<p><img src="https://i.imgur.com/94izVsf.png" alt="" /></p>
<p><img src="https://i.imgur.com/eX5D7Z7.png" alt="" /></p>
<p><img src="https://i.imgur.com/CNb8h2A.png" alt="" /></p>
<p><img src="https://i.imgur.com/rB9Ovkc.png" alt="" /></p>
<p><img src="https://i.imgur.com/HsC1xzi.png" alt="" /></p>
<p><img src="https://i.imgur.com/Q1rcS4d.png" alt="" /></p>
<p><img src="https://i.imgur.com/ggpEbLv.png" alt="" /></p>
<pre><code class="language-python">import jsonlines
import itertools
import pandas as pd
from pprint import pprint

import datasets
from datasets import load_dataset
# dataset https://huggingface.co/datasets/c4
#pretrained_dataset = load_dataset("EleutherAI/pile", split="train", streaming=True)

pretrained_dataset = load_dataset("c4", "en", split="train", streaming=True)
n = 5
print("Pretrained dataset:")
top_n = itertools.islice(pretrained_dataset, n)
for i in top_n:
  print(i)
#  Contrast with company finetuning dataset you will be using
filename = "lamini_docs.jsonl"
instruction_dataset_df = pd.read_json(filename, lines=True)
instruction_dataset_df
# Various ways of formatting your data
examples = instruction_dataset_df.to_dict()
text = examples["question"][0] + examples["answer"][0]
text
if "question" in examples and "answer" in examples:
  text = examples["question"][0] + examples["answer"][0]
elif "instruction" in examples and "response" in examples:
  text = examples["instruction"][0] + examples["response"][0]
elif "input" in examples and "output" in examples:
  text = examples["input"][0] + examples["output"][0]
else:
  text = examples["text"][0]
prompt_template_qa = """### Question:
{question}

### Answer:
{answer}"""
question = examples["question"][0]
answer = examples["answer"][0]

text_with_prompt_template = prompt_template_qa.format(question=question, answer=answer)
text_with_prompt_template
prompt_template_q = """### Question:
{question}

### Answer:"""
num_examples = len(examples["question"])
finetuning_dataset_text_only = []
finetuning_dataset_question_answer = []
for i in range(num_examples):
  question = examples["question"][i]
  answer = examples["answer"][i]

  text_with_prompt_template_qa = prompt_template_qa.format(question=question, answer=answer)
  finetuning_dataset_text_only.append({"text": text_with_prompt_template_qa})

  text_with_prompt_template_q = prompt_template_q.format(question=question)
  finetuning_dataset_question_answer.append({"question": text_with_prompt_template_q, "answer": answer})
pprint(finetuning_dataset_text_only[0])
pprint(finetuning_dataset_question_answer[0])
#  Common ways of storing your data
with jsonlines.open(f'lamini_docs_processed.jsonl', 'w') as writer:
    writer.write_all(finetuning_dataset_question_answer)
finetuning_dataset_name = "lamini/lamini_docs"
finetuning_dataset = load_dataset(finetuning_dataset_name)
print(finetuning_dataset)
</code></pre>
<h2 id="instruction-finetuning"><a class="header" href="#instruction-finetuning">Instruction Finetuning</a></h2>
<ul>
<li>GPT 3 -&gt; chat gpt</li>
</ul>
<p><img src="https://i.imgur.com/KW61A2I.png" alt="" /></p>
<p><img src="https://i.imgur.com/MriMFoJ.png" alt="" /></p>
<p><img src="https://i.imgur.com/mSzD9LY.png" alt="" /></p>
<p><img src="https://i.imgur.com/cjnmpQ6.png" alt="" /></p>
<p><img src="https://i.imgur.com/t3zPpYM.png" alt="" /></p>
<pre><code class="language-python">import itertools
import jsonlines

from datasets import load_dataset
from pprint import pprint

from llama import BasicModelRunner
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
#  Load instruction tuned dataset
instruction_tuned_dataset = load_dataset("tatsu-lab/alpaca", split="train", streaming=True)
m = 5
print("Instruction-tuned dataset:")
top_m = list(itertools.islice(instruction_tuned_dataset, m))
for j in top_m:
  print(j)
#  Two prompt templates
prompt_template_with_input = """Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Input:
{input}

### Response:"""

prompt_template_without_input = """Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Response:"""
#  Hydrate prompts (add data to prompts)
processed_data = []
for j in top_m:
  if not j["input"]:
    processed_prompt = prompt_template_without_input.format(instruction=j["instruction"])
  else:
    processed_prompt = prompt_template_with_input.format(instruction=j["instruction"], input=j["input"])

  processed_data.append({"input": processed_prompt, "output": j["output"]})
pprint(processed_data[0])
# Save data to jsonl
with jsonlines.open(f'alpaca_processed.jsonl', 'w') as writer:
    writer.write_all(processed_data)
#  Compare non-instruction-tuned vs. instruction-tuned models
dataset_path_hf = "lamini/alpaca"
dataset_hf = load_dataset(dataset_path_hf)
print(dataset_hf)
non_instruct_model = BasicModelRunner("meta-llama/Llama-2-7b-hf")
non_instruct_output = non_instruct_model("Tell me how to train my dog to sit")
print("Not instruction-tuned output (Llama 2 Base):", non_instruct_output)
instruct_model = BasicModelRunner("meta-llama/Llama-2-7b-chat-hf")
instruct_output = instruct_model("Tell me how to train my dog to sit")
print("Instruction-tuned output (Llama 2): ", instruct_output)

chatgpt = BasicModelRunner("chat-gpt")
instruct_output_chatgpt = chatgpt("Tell me how to train my dog to sit")
print("Instruction-tuned output (ChatGPT): ", instruct_output_chatgpt)
# Try smaller models
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-70m")
model = AutoModelForCausalLM.from_pretrained("EleutherAI/pythia-70m")
def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):
  # Tokenize
  input_ids = tokenizer.encode(
          text,
          return_tensors="pt",
          truncation=True,
          max_length=max_input_tokens
  )

  # Generate
  device = model.device
  generated_tokens_with_prompt = model.generate(
    input_ids=input_ids.to(device),
    max_length=max_output_tokens
  )

  # Decode
  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)

  # Strip the prompt
  generated_text_answer = generated_text_with_prompt[0][len(text):]

  return generated_text_answer
test_sample = finetuning_dataset["test"][0]
print(test_sample)

print(inference(test_sample["question"], model, tokenizer))
# Compare to finetuned small model
instruction_model = AutoModelForCausalLM.from_pretrained("lamini/lamini_docs_finetuned")
print(inference(test_sample["question"], instruction_model, tokenizer))
# Pssst! If you were curious how to upload your own dataset to Huggingface
# Here is how we did it

# !pip install huggingface_hub
# !huggingface-cli login

# import pandas as pd
# import datasets
# from datasets import Dataset

# finetuning_dataset = Dataset.from_pandas(pd.DataFrame(data=finetuning_dataset))
# finetuning_dataset.push_to_hub(dataset_path_hf)
</code></pre>
<h2 id="data-preparation"><a class="header" href="#data-preparation">Data preparation</a></h2>
<p><img src="https://i.imgur.com/eofv0yl.png" alt="" /></p>
<p><img src="https://i.imgur.com/anPS7sO.png" alt="" /></p>
<p><img src="https://i.imgur.com/4CRgyI5.png" alt="" /></p>
<pre><code class="language-python">import pandas as pd
import datasets

from pprint import pprint
from transformers import AutoTokenizer
#  Tokenizing text
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-70m")
text = "Hi, how are you?"
encoded_text = tokenizer(text)["input_ids"]
encoded_text
decoded_text = tokenizer.decode(encoded_text)
print("Decoded tokens back into text: ", decoded_text)
# Tokenize multiple texts at once
list_texts = ["Hi, how are you?", "I'm good", "Yes"]
encoded_texts = tokenizer(list_texts)
print("Encoded several texts: ", encoded_texts["input_ids"])
# Padding and truncation: input長度不一要做這
tokenizer.pad_token = tokenizer.eos_token 
encoded_texts_longest = tokenizer(list_texts, padding=True)
print("Using padding: ", encoded_texts_longest["input_ids"])
encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)
print("Using truncation: ", encoded_texts_truncation["input_ids"])
tokenizer.truncation_side = "left"
encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)
print("Using left-side truncation: ", encoded_texts_truncation_left["input_ids"])
encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)
print("Using both padding and truncation: ", encoded_texts_both["input_ids"])
#  Prepare instruction dataset
import pandas as pd

filename = "lamini_docs.jsonl"
instruction_dataset_df = pd.read_json(filename, lines=True)
examples = instruction_dataset_df.to_dict()

if "question" in examples and "answer" in examples:
  text = examples["question"][0] + examples["answer"][0]
elif "instruction" in examples and "response" in examples:
  text = examples["instruction"][0] + examples["response"][0]
elif "input" in examples and "output" in examples:
  text = examples["input"][0] + examples["output"][0]
else:
  text = examples["text"][0]

prompt_template = """### Question:
{question}

### Answer:"""

num_examples = len(examples["question"])
finetuning_dataset = []
for i in range(num_examples):
  question = examples["question"][i]
  answer = examples["answer"][i]
  text_with_prompt_template = prompt_template.format(question=question)
  finetuning_dataset.append({"question": text_with_prompt_template, "answer": answer})

from pprint import pprint
print("One datapoint in the finetuning dataset:")
pprint(finetuning_dataset[0])
# Tokenize a single example
text = finetuning_dataset[0]["question"] + finetuning_dataset[0]["answer"]
tokenized_inputs = tokenizer(
    text,
    return_tensors="np",
    padding=True
)
print(tokenized_inputs["input_ids"])
max_length = 2048
max_length = min(
    tokenized_inputs["input_ids"].shape[1],
    max_length,
)
tokenized_inputs = tokenizer(
    text,
    return_tensors="np",
    truncation=True,
    max_length=max_length
)
tokenized_inputs["input_ids"]
# Tokenize the instruction dataset
def tokenize_function(examples):
    if "question" in examples and "answer" in examples:
      text = examples["question"][0] + examples["answer"][0]
    elif "input" in examples and "output" in examples:
      text = examples["input"][0] + examples["output"][0]
    else:
      text = examples["text"][0]

    tokenizer.pad_token = tokenizer.eos_token
    tokenized_inputs = tokenizer(
        text,
        return_tensors="np",
        padding=True,
    )

    max_length = min(
        tokenized_inputs["input_ids"].shape[1],
        2048
    )
    tokenizer.truncation_side = "left"
    tokenized_inputs = tokenizer(
        text,
        return_tensors="np",
        truncation=True,
        max_length=max_length
    )

    return tokenized_inputs
finetuning_dataset_loaded = datasets.load_dataset("json", data_files=filename, split="train")

tokenized_dataset = finetuning_dataset_loaded.map(
    tokenize_function,
    batched=True,
    batch_size=1,
    drop_last_batch=True
)

print(tokenized_dataset)
tokenized_dataset = tokenized_dataset.add_column("labels", tokenized_dataset["input_ids"])
# Prepare test/train splits
split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)
print(split_dataset)
# Some datasets for you to try
finetuning_dataset_path = "lamini/lamini_docs"
finetuning_dataset = datasets.load_dataset(finetuning_dataset_path)
print(finetuning_dataset)
taylor_swift_dataset = "lamini/taylor_swift"
bts_dataset = "lamini/bts"
open_llms = "lamini/open_llms"
dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)
print(dataset_swiftie["train"][1])
# This is how to push your own dataset to your Huggingface hub
# !pip install huggingface_hub
# !huggingface-cli login
# split_dataset.push_to_hub(dataset_path_hf)
</code></pre>
<h2 id="traning-process"><a class="header" href="#traning-process">Traning process</a></h2>
<p><img src="https://i.imgur.com/ILPKHr8.png" alt="" /></p>
<p><img src="https://i.imgur.com/ubnMHDQ.png" alt="" /></p>
<pre><code class="language-python"># Technically, it's only a few lines of code to run on GPUs (elsewhere, ie. on Lamini).
from llama import BasicModelRunner
model = BasicModelRunner("EleutherAI/pythia-410m") 
model.load_data_from_jsonlines("lamini_docs.jsonl", input_key="question", output_key="answer")
model.train(is_public=True) 
%% 1. Choose base model.
2. Load data.
3. Train it. Returns a model ID, dashboard, and playground interface. %%
#  Let's look under the hood at the core code running this! This is the open core of Lamini's `llama` library :)
import datasets
import tempfile
import logging
import random
import config
import os
import yaml
import time
import torch
import transformers
import pandas as pd
import jsonlines

from utilities import * # tokenlizer
from transformers import AutoTokenizer
from transformers import AutoModelForCausalLM
from transformers import TrainingArguments
from transformers import AutoModelForCausalLM
from llama import BasicModelRunner


logger = logging.getLogger(__name__)
global_config = None
# Load the Lamini docs dataset
dataset_name = "lamini_docs.jsonl"
dataset_path = f"/content/{dataset_name}"
use_hf = False
dataset_path = "lamini/lamini_docs"
use_hf = True
# Set up the model, training config, and tokenizer
model_name = "EleutherAI/pythia-70m"
training_config = {
    "model": {
        "pretrained_name": model_name,
        "max_length" : 2048
    },
    "datasets": {
        "use_hf": use_hf,
        "path": dataset_path
    },
    "verbose": True
}
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
train_dataset, test_dataset = tokenize_and_split_data(training_config, tokenizer)

print(train_dataset)
print(test_dataset)
# Load the base model
base_model = AutoModelForCausalLM.from_pretrained(model_name)
device_count = torch.cuda.device_count()
if device_count &gt; 0:
    logger.debug("Select GPU device")
    device = torch.device("cuda")
else:
    logger.debug("Select CPU device")
    device = torch.device("cpu")
base_model.to(device)
# Define function to carry out inference
def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):
  # Tokenize
  input_ids = tokenizer.encode(
          text,
          return_tensors="pt",
          truncation=True,
          max_length=max_input_tokens
  )

  # Generate
  device = model.device
  generated_tokens_with_prompt = model.generate(
    input_ids=input_ids.to(device),
    max_length=max_output_tokens
  )

  # Decode
  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)

  # Strip the prompt
  generated_text_answer = generated_text_with_prompt[0][len(text):]

  return generated_text_answer
# Try the base model
test_text = test_dataset[0]['question']
print("Question input (test):", test_text)
print(f"Correct answer from Lamini docs: {test_dataset[0]['answer']}")
print("Model's answer: ")
print(inference(test_text, base_model, tokenizer))
# Setup training
max_steps = 3
trained_model_name = f"lamini_docs_{max_steps}_steps"
output_dir = trained_model_name
training_args = TrainingArguments(

  # Learning rate
  learning_rate=1.0e-5,

  # Number of training epochs
  num_train_epochs=1,

  # Max steps to train for (each step is a batch of data)
  # Overrides num_train_epochs, if not -1
  max_steps=max_steps,

  # Batch size for training
  per_device_train_batch_size=1,

  # Directory to save model checkpoints
  output_dir=output_dir,

  # Other arguments
  overwrite_output_dir=False, # Overwrite the content of the output directory
  disable_tqdm=False, # Disable progress bars
  eval_steps=120, # Number of update steps between two evaluations
  save_steps=120, # After # steps model is saved
  warmup_steps=1, # Number of warmup steps for learning rate scheduler
  per_device_eval_batch_size=1, # Batch size for evaluation
  evaluation_strategy="steps",
  logging_strategy="steps",
  logging_steps=1,
  optim="adafactor",
  gradient_accumulation_steps = 4,
  gradient_checkpointing=False,

  # Parameters for early stopping
  load_best_model_at_end=True,
  save_total_limit=1,
  metric_for_best_model="eval_loss",
  greater_is_better=False
)
model_flops = (
  base_model.floating_point_ops(
    {
       "input_ids": torch.zeros(
           (1, training_config["model"]["max_length"])
      )
    }
  )
  * training_args.gradient_accumulation_steps
)

print(base_model)
print("Memory footprint", base_model.get_memory_footprint() / 1e9, "GB")
print("Flops", model_flops / 1e9, "GFLOPs")
trainer = Trainer(
    model=base_model,
    model_flops=model_flops,
    total_steps=max_steps,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
)
# Train a few steps
training_output = trainer.train()
# Save model locally
save_dir = f'{output_dir}/final'

trainer.save_model(save_dir)
print("Saved model to:", save_dir)
finetuned_slightly_model = AutoModelForCausalLM.from_pretrained(save_dir, local_files_only=True)
finetuned_slightly_model.to(device) 
# Run slightly trained model
test_question = test_dataset[0]['question']
print("Question input (test):", test_question)

print("Finetuned slightly model's answer: ")
print(inference(test_question, finetuned_slightly_model, tokenizer))
test_answer = test_dataset[0]['answer']
print("Target answer output (test):", test_answer)
# Run same model trained for two epochs
finetuned_longer_model = AutoModelForCausalLM.from_pretrained("lamini/lamini_docs_finetuned")
tokenizer = AutoTokenizer.from_pretrained("lamini/lamini_docs_finetuned")

finetuned_longer_model.to(device)
print("Finetuned longer model's answer: ")
print(inference(test_question, finetuned_longer_model, tokenizer))
# Run much larger trained model and explore moderation
bigger_finetuned_model = BasicModelRunner(model_name_to_id["bigger_model_name"])
bigger_finetuned_output = bigger_finetuned_model(test_question)
print("Bigger (2.8B) finetuned model (test): ", bigger_finetuned_output)
count = 0
for i in range(len(train_dataset)):
 if "keep the discussion relevant to Lamini" in train_dataset[i]["answer"]:
  print(i, train_dataset[i]["question"], train_dataset[i]["answer"])
  count += 1
print(count)
# Explore moderation using small model
base_tokenizer = AutoTokenizer.from_pretrained("EleutherAI/pythia-70m")
base_model = AutoModelForCausalLM.from_pretrained("EleutherAI/pythia-70m")
print(inference("What do you think of Mars?", base_model, base_tokenizer))
#  Now try moderation with finetuned small model
print(inference("What do you think of Mars?", finetuned_longer_model, tokenizer))
# Finetune a model in 3 lines of code using Lamini
model = BasicModelRunner("EleutherAI/pythia-410m") 
model.load_data_from_jsonlines("lamini_docs.jsonl", input_key="question", output_key="answer")
model.train(is_public=True) 
out = model.evaluate()
lofd = []
for e in out['eval_results']:
    q  = f"{e['input']}"
    at = f"{e['outputs'][0]['output']}"
    ab = f"{e['outputs'][1]['output']}"
    di = {'question': q, 'trained model': at, 'Base Model' : ab}
    lofd.append(di)
df = pd.DataFrame.from_dict(lofd)
style_df = df.style.set_properties(**{'text-align': 'left'})
style_df = style_df.set_properties(**{"vertical-align": "text-top"})
style_df

</code></pre>
<h2 id="evaluation--iteration"><a class="header" href="#evaluation--iteration">Evaluation &amp; iteration</a></h2>
<p><img src="https://i.imgur.com/QpZlbQi.png" alt="" /></p>
<p><img src="https://i.imgur.com/Jaj4v96.png" alt="" /></p>
<p><img src="https://i.imgur.com/NB2PWD3.png" alt="" /></p>
<pre><code class="language-python"># Technically, there are very few steps to run it on GPUs, elsewhere (ie. on Lamini).
finetuned_model = BasicModelRunner(
    "lamini/lamini_docs_finetuned"
)
finetuned_output = finetuned_model(
    test_dataset_list # batched!
) 
# Let's look again under the hood! This is the open core code of Lamini's `llama` library :)
import datasets
import tempfile
import logging
import random
import config
import os
import yaml
import logging
import difflib
import pandas as pd

import transformers
import datasets
import torch

from tqdm import tqdm
from utilities import *
from transformers import AutoTokenizer, AutoModelForCausalLM

logger = logging.getLogger(__name__)
global_config = None
dataset = datasets.load_dataset("lamini/lamini_docs")

test_dataset = dataset["test"]
print(test_dataset[0]["question"])
print(test_dataset[0]["answer"])
model_name = "lamini/lamini_docs_finetuned"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)
#  Setup a really basic evaluation function
def is_exact_match(a, b):
    return a.strip() == b.strip()
model.eval()
def inference(text, model, tokenizer, max_input_tokens=1000, max_output_tokens=100):
  # Tokenize
  tokenizer.pad_token = tokenizer.eos_token
  input_ids = tokenizer.encode(
      text,
      return_tensors="pt",
      truncation=True,
      max_length=max_input_tokens
  )

  # Generate
  device = model.device
  generated_tokens_with_prompt = model.generate(
    input_ids=input_ids.to(device),
    max_length=max_output_tokens
  )

  # Decode
  generated_text_with_prompt = tokenizer.batch_decode(generated_tokens_with_prompt, skip_special_tokens=True)

  # Strip the prompt
  generated_text_answer = generated_text_with_prompt[0][len(text):]

  return generated_text_answer
# Run model and compare to expected answer
test_question = test_dataset[0]["question"]
generated_answer = inference(test_question, model, tokenizer)
print(test_question)
print(generated_answer)
answer = test_dataset[0]["answer"]
print(answer)
exact_match = is_exact_match(generated_answer, answer)
print(exact_match)
# Run over entire dataset
n = 10
metrics = {'exact_matches': []}
predictions = []
for i, item in tqdm(enumerate(test_dataset)):
    print("i Evaluating: " + str(item))
    question = item['question']
    answer = item['answer']

    try:
      predicted_answer = inference(question, model, tokenizer)
    except:
      continue
    predictions.append([predicted_answer, answer])

    #fixed: exact_match = is_exact_match(generated_answer, answer)
    exact_match = is_exact_match(predicted_answer, answer)
    metrics['exact_matches'].append(exact_match)

    if i &gt; n and n != -1:
      break
print('Number of exact matches: ', sum(metrics['exact_matches']))
df = pd.DataFrame(predictions, columns=["predicted_answer", "target_answer"])
print(df)
#  Evaluate all the data
evaluation_dataset_path = "lamini/lamini_docs_evaluation"
evaluation_dataset = datasets.load_dataset(evaluation_dataset_path)
pd.DataFrame(evaluation_dataset)
# Try the ARC benchmark
!python lm-evaluation-harness/main.py --model hf-causal --model_args pretrained=lamini/lamini_docs_finetuned --tasks arc_easy --device cpu
</code></pre>
<h2 id="consider-an-getting-start"><a class="header" href="#consider-an-getting-start">consider an getting start</a></h2>
<p><img src="https://i.imgur.com/IZJz9JJ.png" alt="" /></p>
<p><img src="https://i.imgur.com/hYe9zML.png" alt="" /></p>
<p><img src="https://i.imgur.com/n6wwBoX.png" alt="" /></p>
<p><img src="https://i.imgur.com/GSqcIS6.png" alt="" /></p>
<p><img src="https://i.imgur.com/hLfaoiW.png" alt="" /></p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<h2 id="ref"><a class="header" href="#ref">Ref</a></h2>
<ul>
<li>https://learn.deeplearning.ai/finetuning-large-language-models</li>
<li></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../../posts/llm/20231101-generative-ai-for-everyone.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../../posts/llm/20231110-80分鐘快速了解大型語言模型-5-30有咒術迴戰雷.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../../posts/llm/20231101-generative-ai-for-everyone.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../../posts/llm/20231110-80分鐘快速了解大型語言模型-5-30有咒術迴戰雷.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="../../elasticlunr.min.js"></script>
        <script src="../../mark.min.js"></script>
        <script src="../../searcher.js"></script>

        <script src="../../clipboard.min.js"></script>
        <script src="../../highlight.js"></script>
        <script src="../../book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
